# ğŸ” Chat with PDF Using Hybrid RAG

This project combines the best of semantic and keyword-based retrieval to let you chat intelligently with PDF documents. By leveraging Hybrid Retrieval-Augmented Generation (RAG), it provides more accurate and contextually relevant answers to your questions using both vector similarity and BM25 scoring.

---

## âœ¨ Features

- ğŸ“¥ Upload and parse PDF documents
- âœ‚ï¸ Split content into overlapping text chunks
- ğŸ§  Use Ollama embeddings for semantic search
- ğŸ§¾ Use BM25 algorithm for keyword relevance
- ğŸ”— Combine both using Hybrid RAG (Ensemble Retriever)
- ğŸ’¬ Ask natural language questions and get concise, accurate answers
- âš¡ Powered by Ollama's deepseek-r1:14b local LLM

---

## ğŸ›  Tech Stack

- Python
- Streamlit (UI)
- LangChain (LLMs, chaining, retrievers)
- LangChain Community Components
- PDFPlumber (PDF parsing)
- Ollama + deepseek-r1:14b (LLM & Embeddings)
- InMemoryVectorStore
- BM25Retriever (keyword search)
- EnsembleRetriever (Hybrid RAG)
- NLTK for tokenization

---

## ğŸ“‚ Project Structure

```
hybrid_pdf_rag/
â”œâ”€â”€ hybrid_pdf_rag.py       # Streamlit application and core RAG logic
â”œâ”€â”€ pdfs/                   # Folder to store uploaded PDF files
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## ğŸš€ How It Works

1. ğŸ“„ Upload a PDF via the interface.
2. ğŸ” The document is split into chunks and indexed using:
   - Semantic vector embeddings (Ollama)
   - BM25 keyword scores
3. ğŸ§  Both retrieval scores are combined using EnsembleRetriever.
4. ğŸ—£ï¸ You ask a question in natural language.
5. ğŸ“š The system finds the most relevant content and generates an answer using deepseek-r1:14b.

---

## ğŸ“¦ Installation

Clone the repository:

```bash
git clone https://github.com/yourusername/ollama-project.git
cd ollama-project/hybrid_pdf_rag
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Install NLTK tokenizer (used by BM25):

```bash
python -m nltk.downloader punkt
```

Make sure Ollama is running with the required model:

```bash
ollama run deepseek-r1:14b
```

---

## â–¶ï¸ Run the App

Launch the app with Streamlit:

```bash
streamlit run hybrid_pdf_rag.py
```

- Upload your PDF
- Ask a question in the chat input
- View the assistant's answer and validate the context

---

## ğŸ“¸ UI Preview

(Include a screenshot or screen recording here for better visualization.)

---

## ğŸ§ª Example Use Cases

- Summarize academic research papers
- Extract insights from product manuals or policy docs
- Review contracts or legal files with hybrid context awareness
- Build internal knowledge assistants

---

## ğŸ“Œ Notes

- PDF files are saved in the pdfs/ directory locally.
- All data is stored in-memory and resets when the app is restarted.
- The retriever combines semantic and lexical (BM25) search for robust results.

---

## ğŸ¤ Contributing

Pull requests and issue reports are welcome! Letâ€™s improve this hybrid AI agent together.

---

## ğŸ“§ Contact & Support

ğŸ’¡ Have questions or suggestions? Feel free to reach out!  
ğŸ“© Email: shaishavsurati06@email.com  
ğŸ”— LinkedIn: [Shaishav Surati ğŸ‡®ğŸ‡³](https://linkedin.com/in/shaishavsurati)

ğŸš€ Letâ€™s build amazing AI Agents together! ğŸ¯